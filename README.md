# web-crawler
I built a distributed-style crawler with domain-level politeness, deduplication, and priority scheduling. The system is intentionally modular so workers can scale horizontally. I focused on correctness and crawl efficiency rather than just fetching pages.
